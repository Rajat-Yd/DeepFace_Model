{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyPWEFkwSSmwlIc0GXRhXckq"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yflLVNim7OV0"
      },
      "outputs": [],
      "source": [
        "!pip install deepface opencv-python"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import deepface\n",
        "from IPython.display import display, clear_output\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "wCvz4_fx7cLB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def show_camera():\n",
        "    cap = cv2.VideoCapture(1)\n",
        "    while True:\n",
        "        ret, frame = cap.read()\n",
        "        display(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
        "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "            break\n",
        "    cap.release()\n",
        "    cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "tbeejSqE7l32"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def real_time_face_recognition():\n",
        "    cap = cv2.VideoCapture(0)\n",
        "    deepface.set_verbose(False)\n",
        "\n",
        "    while True:\n",
        "        ret, frame = cap.read()\n",
        "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "        faces = deepface.detect_faces(frame_rgb)\n",
        "\n",
        "        for face in faces:\n",
        "            x, y, w, h = face['box']\n",
        "            cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
        "\n",
        "            face_rgb = frame_rgb[y:y+h, x:x+w]\n",
        "            face_resized = cv2.resize(face_rgb, (224, 224))\n",
        "\n",
        "            obj = deepface.analyze(face_resized, actions=['emotion', 'age', 'race'], enforce_detection=False)\n",
        "\n",
        "            emotion = obj[0]['dominant_emotion']\n",
        "            age = obj[0]['age']\n",
        "            race = obj[0]['race']\n",
        "\n",
        "            cv2.putText(frame, f\"Emotion: {emotion}\", (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)\n",
        "            cv2.putText(frame, f\"Age: {age} years old\", (x, y + h + 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)\n",
        "            cv2.putText(frame, f\"Race: {race}\", (x, y + h + 30), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)\n",
        "\n",
        "        display(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
        "\n",
        "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "            break\n",
        "\n",
        "    cap.release()\n",
        "    cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "OzxrZ8Q_7qpL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "show_camera()"
      ],
      "metadata": {
        "id": "EhwC8mHj7uBm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5LuLmfGB8BkV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}